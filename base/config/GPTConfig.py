

class GPT2_CONFIG_124M (object):
    vocab_size = 50257
    context_len = 16 # 256  #
    # context_length = 1024
    embed_dim= 768
    embed_dim_ff_dim = 768 * 4  # 3072
    num_heads = 12
    num_layers = 12
    drop_rate = 0.1
    qkv_bias = False

