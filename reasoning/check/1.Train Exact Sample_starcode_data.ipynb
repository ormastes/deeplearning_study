{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349f03dd-5c28-4a46-b7ac-720e7b3648a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and setup\n",
    "# ------------------------------------------------\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import urllib.request\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, logging as hf_logging\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import ReasoningChat\n",
    "from ExactSampleDataset import ExactSampleDataset\n",
    "from ExactSampleTrainLoop import train_exact\n",
    "from Config import SimpleConfig\n",
    "\n",
    "# Suppress warnings from Transformers\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7179030d-779b-41e5-bb61-bdc8e06c2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch random seed idiom\n",
    "# ------------------------------------------------\n",
    "\n",
    "def set_random_seed(seed: int = 42):\n",
    "    # Set the seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "    # Set the seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "    # Set the seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # Ensure deterministic behavior in cuDNN (may impact performance)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a585214-23de-49bf-a185-c4269ea3291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Settings\n",
    "# ------------------------------------------------\n",
    "class ExactSampleConfig(SimpleConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.learning_rate = 1e-6\n",
    "        self.weight_decay = 0.1\n",
    "        self.num_epochs = 1200\n",
    "        self.max_new_tokens = 0.1\n",
    "        self.context_len = 256  # Maximum sequence length\n",
    "        self.num_batches = 1  # Batch size for DataLoader\n",
    "        self.prompt_len = 829\n",
    "\n",
    "    def get_training_layers(self, model):\n",
    "        # get first and last layer's parameters\n",
    "        params = list(model.parameters())\n",
    "        # merge first and last layer's parameters\n",
    "        return params # params[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9d47d0-ae75-41ff-925b-6a0c5515c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger Stub\n",
    "# --------------------------\n",
    "class LogLevel:\n",
    "    ERROR = 40\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    _instance = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.level = LogLevel.ERROR\n",
    "\n",
    "    @classmethod\n",
    "    def get_instance(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = Logger()\n",
    "        return cls._instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf877a2-f84c-47f6-a894-3e8da3424757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding side: right\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Config and Settings\n",
    "# ------------------------------------------------\n",
    "\n",
    "config = ExactSampleConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d884b3c-f2fc-4da8-849b-58dc0ff37c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and Tokenizer\n",
    "# ------------------------------------------------\n",
    "model, optimizer, tokenizer = config.load(force_new=True)\n",
    "max_id = tokenizer.vocab_size\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "print(\"Padding side:\", tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd312048-3ff4-4a5e-bdc8-a8b05ee42b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check config pad text\n",
    "# ------------------------------------------------\n",
    "\n",
    "config.pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aabe1f7-462a-4369-925e-176a42e4b5aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 9844\n",
      "Dataset length: 1693\n",
      "Train Loader done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorBoard SummaryWriter\n",
    "# ------------------------------------------------\n",
    "\n",
    "tb_log_dir = os.path.join(config.model_path, \"tensorboard_logs\")\n",
    "writer = SummaryWriter(log_dir=tb_log_dir)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch =  torch.tensor(batch)\n",
    "    m = config.max_context_len # max([batch[i].shape[0] for i in range(len(batch))])\n",
    "    pad = tokenizer.pad_token_id\n",
    "    # fill padding tokens\n",
    "    batch = [torch.cat([batch[i], torch.tensor([pad] * (m - batch[i].shape[0]), dtype=torch.long)]) for i in range(len(batch))]\n",
    "    batch = torch.stack(batch, dim=0)\n",
    "    return batch\n",
    "\n",
    "dataset = ExactSampleDataset(tokenizer, config)\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "#summary(model, (2, 256, tokenizer.vocab_size))\n",
    "#for name, param in model.named_parameters():\n",
    "    #print(name, param.size())\n",
    "config.num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b543f62-d08c-42d3-8caf-641e2da56bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.Size([49152, 3072])\n",
      "model.layers.0.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.0.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.0.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.0.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.0.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.0.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.0.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.0.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.0.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.0.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.0.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.0.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.0.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.0.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.0.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.0.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.1.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.1.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.1.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.1.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.1.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.1.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.1.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.1.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.1.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.1.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.1.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.1.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.1.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.1.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.1.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.1.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.2.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.2.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.2.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.2.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.2.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.2.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.2.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.2.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.2.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.2.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.2.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.2.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.2.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.2.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.2.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.2.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.3.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.3.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.3.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.3.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.3.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.3.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.3.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.3.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.3.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.3.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.3.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.3.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.3.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.3.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.3.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.3.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.4.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.4.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.4.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.4.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.4.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.4.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.4.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.4.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.4.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.4.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.4.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.4.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.4.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.4.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.4.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.4.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.5.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.5.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.5.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.5.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.5.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.5.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.5.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.5.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.5.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.5.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.5.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.5.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.5.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.5.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.5.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.5.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.6.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.6.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.6.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.6.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.6.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.6.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.6.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.6.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.6.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.6.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.6.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.6.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.6.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.6.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.6.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.6.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.7.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.7.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.7.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.7.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.7.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.7.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.7.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.7.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.7.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.7.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.7.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.7.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.7.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.7.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.7.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.7.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.8.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.8.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.8.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.8.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.8.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.8.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.8.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.8.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.8.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.8.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.8.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.8.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.8.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.8.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.8.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.8.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.9.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.9.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.9.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.9.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.9.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.9.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.9.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.9.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.9.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.9.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.9.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.9.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.9.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.9.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.9.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.9.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.10.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.10.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.10.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.10.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.10.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.10.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.10.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.10.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.10.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.10.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.10.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.10.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.10.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.10.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.10.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.10.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.11.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.11.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.11.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.11.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.11.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.11.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.11.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.11.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.11.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.11.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.11.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.11.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.11.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.11.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.11.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.11.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.12.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.12.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.12.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.12.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.12.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.12.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.12.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.12.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.12.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.12.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.12.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.12.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.12.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.12.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.12.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.12.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.13.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.13.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.13.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.13.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.13.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.13.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.13.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.13.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.13.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.13.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.13.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.13.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.13.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.13.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.13.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.13.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.14.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.14.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.14.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.14.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.14.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.14.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.14.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.14.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.14.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.14.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.14.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.14.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.14.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.14.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.14.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.14.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.15.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.15.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.15.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.15.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.15.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.15.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.15.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.15.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.15.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.15.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.15.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.15.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.15.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.15.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.15.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.15.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.16.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.16.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.16.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.16.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.16.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.16.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.16.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.16.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.16.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.16.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.16.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.16.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.16.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.16.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.16.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.16.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.17.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.17.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.17.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.17.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.17.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.17.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.17.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.17.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.17.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.17.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.17.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.17.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.17.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.17.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.17.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.17.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.18.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.18.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.18.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.18.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.18.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.18.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.18.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.18.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.18.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.18.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.18.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.18.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.18.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.18.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.18.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.18.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.19.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.19.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.19.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.19.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.19.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.19.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.19.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.19.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.19.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.19.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.19.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.19.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.19.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.19.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.19.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.19.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.20.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.20.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.20.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.20.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.20.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.20.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.20.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.20.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.20.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.20.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.20.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.20.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.20.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.20.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.20.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.20.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.21.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.21.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.21.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.21.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.21.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.21.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.21.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.21.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.21.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.21.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.21.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.21.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.21.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.21.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.21.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.21.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.22.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.22.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.22.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.22.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.22.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.22.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.22.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.22.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.22.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.22.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.22.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.22.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.22.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.22.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.22.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.22.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.23.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.23.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.23.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.23.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.23.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.23.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.23.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.23.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.23.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.23.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.23.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.23.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.23.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.23.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.23.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.23.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.24.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.24.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.24.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.24.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.24.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.24.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.24.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.24.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.24.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.24.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.24.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.24.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.24.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.24.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.24.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.24.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.25.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.25.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.25.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.25.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.25.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.25.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.25.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.25.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.25.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.25.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.25.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.25.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.25.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.25.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.25.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.25.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.26.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.26.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.26.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.26.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.26.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.26.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.26.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.26.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.26.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.26.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.26.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.26.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.26.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.26.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.26.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.26.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.27.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.27.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.27.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.27.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.27.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.27.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.27.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.27.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.27.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.27.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.27.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.27.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.27.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.27.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.27.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.27.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.28.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.28.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.28.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.28.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.28.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.28.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.28.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.28.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.28.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.28.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.28.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.28.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.28.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.28.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.28.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.28.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.layers.29.self_attn.q_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.29.self_attn.q_proj.bias torch.Size([3072])\n",
      "model.layers.29.self_attn.k_proj.weight torch.Size([256, 3072])\n",
      "model.layers.29.self_attn.k_proj.bias torch.Size([256])\n",
      "model.layers.29.self_attn.v_proj.weight torch.Size([256, 3072])\n",
      "model.layers.29.self_attn.v_proj.bias torch.Size([256])\n",
      "model.layers.29.self_attn.o_proj.weight torch.Size([3072, 3072])\n",
      "model.layers.29.self_attn.o_proj.bias torch.Size([3072])\n",
      "model.layers.29.mlp.c_fc.weight torch.Size([12288, 3072])\n",
      "model.layers.29.mlp.c_fc.bias torch.Size([12288])\n",
      "model.layers.29.mlp.c_proj.weight torch.Size([3072, 12288])\n",
      "model.layers.29.mlp.c_proj.bias torch.Size([3072])\n",
      "model.layers.29.input_layernorm.weight torch.Size([3072])\n",
      "model.layers.29.input_layernorm.bias torch.Size([3072])\n",
      "model.layers.29.post_attention_layernorm.weight torch.Size([3072])\n",
      "model.layers.29.post_attention_layernorm.bias torch.Size([3072])\n",
      "model.norm.weight torch.Size([3072])\n",
      "model.norm.bias torch.Size([3072])\n"
     ]
    }
   ],
   "source": [
    "# Print model structure\n",
    "# ------------------------------------------------\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e8cfbf-40f7-44ae-9770-322476707215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard SummaryWriter\n",
    "# Ref: https://blog.gopenai.com/coding-grpo-from-scratch-a-guide-to-distributed-implementation-with-qwen2-5-1-5b-instruct-59b34227edac\n",
    "# ------------------------------------------------\n",
    "\n",
    "def selective_log_softmax(logits, input_ids):\n",
    "    log_probs = nn.functional.log_softmax(logits, dim=-1)\n",
    "    return log_probs.gather(dim=-1, index=input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "def compute_log_probs(model, input_ids, attention_mask, logits_to_keep):\n",
    "    logits = model(input_ids=input_ids, attention_mask=attention_mask).logits[:, :-1, :]\n",
    "    input_ids = input_ids[:, -logits_to_keep:]\n",
    "    logits = logits[:, -logits_to_keep:, :]\n",
    "    return selective_log_softmax(logits, input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c39b383-6aff-4eee-a491-9243e8ce9af2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16ed4282c0e4b63a99420ae1e261b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09bcecb93d842999d68dcedc2295cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6adb002adde4460b5c94c2bfbba9431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9838b8154d140229f05af1621fa2b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/64 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32987d2fcec425086518a732bc5dc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00064.parquet:   0%|          | 0.00/940M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04b8be60fff483195033b2f9d68020c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00064.parquet:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc4a3627b144f22813f247d9038666c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00064.parquet:   0%|          | 0.00/927M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28ddf4ccbbe4a1191a838d5c5fe3f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00064.parquet:   0%|          | 0.00/925M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0652877f6d6745bd8cb7470594bebbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00064.parquet:   0%|          | 0.00/927M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fe60da212e44e19803aa61568bcd19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00064.parquet:   0%|          | 0.00/930M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5d6bf370ad49f99c48d014a9bf7bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00064.parquet:   0%|          | 0.00/915M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5a9f4d6e95493dabc37fc47e071811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00064.parquet:   0%|          | 0.00/914M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e26b244409e4219bff6a498996289db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00064.parquet:   0%|          | 0.00/908M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cba66fa9eb74c9191197dab92656739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00009-of-00064.parquet:   0%|          | 0.00/923M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf3033240374d1ebc9b19e7d888b1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00010-of-00064.parquet:   0%|          | 0.00/994M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbaf6999afe43c29eb141c4d4fbbc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00011-of-00064.parquet:   0%|          | 0.00/921M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fca1781c4f84b6e9402672012650981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00012-of-00064.parquet:   0%|          | 0.00/944M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b55046f5e374a4da253f5eb0e7f8a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00013-of-00064.parquet:   0%|          | 0.00/920M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1e9efeff8a44d181412cee7b073b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00014-of-00064.parquet:   0%|          | 0.00/922M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb0aa6889a243eba50bc9c1eb648a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00015-of-00064.parquet:   0%|          | 0.00/963M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922768f9acc34fc78aa364e02ef77a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00016-of-00064.parquet:   0%|          | 0.00/916M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472025130bfd4dc9b563e4066dface51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00017-of-00064.parquet:   0%|          | 0.00/938M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377c0f4df66a4f33878d58b88b20b88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00018-of-00064.parquet:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45c4e4888424f1d9c2931f75fb64f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00019-of-00064.parquet:   0%|          | 0.00/926M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189b9007764a461fb31a585e15a23534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00020-of-00064.parquet:   0%|          | 0.00/932M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e822f4afed464e83948f63a6f015be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00021-of-00064.parquet:   0%|          | 0.00/921M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dd96708fc345eca6ef156b07d0b1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00022-of-00064.parquet:   0%|          | 0.00/926M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b75c341f6044786a955ecc47f743159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00023-of-00064.parquet:   0%|          | 0.00/937M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fecbe7d053543db8d72057bf9d73135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00024-of-00064.parquet:   0%|          | 0.00/938M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b147f77c86ae4684bb590867cae6dcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00025-of-00064.parquet:   0%|          | 0.00/917M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413b874033bb4b4ebb88913aba34b9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00026-of-00064.parquet:   0%|          | 0.00/942M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd528acfd9b442359b0ad8134501c564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00027-of-00064.parquet:   0%|          | 0.00/930M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9a5255a3b2439b9b4c28dc8739f8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00028-of-00064.parquet:   0%|          | 0.00/913M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1224e425ee24b529d0a8169317f6444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00029-of-00064.parquet:   0%|          | 0.00/920M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c58717f54e7463399089f010e4f27f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00030-of-00064.parquet:   0%|          | 0.00/931M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34332aa6b4c749d3a164149907d9a8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00031-of-00064.parquet:   0%|          | 0.00/914M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d543375f8540baaa3a677b80fc26c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00032-of-00064.parquet:   0%|          | 0.00/943M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006bc7b6394a44a1829f5c458935cb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00033-of-00064.parquet:   0%|          | 0.00/923M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1132f41e03524a528426c2b9fa41d8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00034-of-00064.parquet:   0%|          | 0.00/920M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5330376ffa6b42d68d105b147d935ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00035-of-00064.parquet:   0%|          | 0.00/928M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ab4b2f6f32410487245078de0486ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00036-of-00064.parquet:   0%|          | 0.00/909M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9b2e258c6d4effb052dd482939247a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00037-of-00064.parquet:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e498eb21405473da8ab90fa601f0354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00038-of-00064.parquet:   0%|          | 0.00/924M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0468a90e8cba4a8ebf2ecaa1ac7ea3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00039-of-00064.parquet:   0%|          | 0.00/913M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc972f8685b415880b899e421f95967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00040-of-00064.parquet:   0%|          | 0.00/926M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d84f84c6c3946ed8bf0d9b25208c291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00041-of-00064.parquet:   0%|          | 0.00/932M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8257efa142fc4e379c5680473b2496d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00042-of-00064.parquet:   0%|          | 0.00/917M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5b4c2be53c40e1a016301698e76044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00043-of-00064.parquet:   0%|          | 0.00/910M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff9121e1147406e8666df795000469c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00044-of-00064.parquet:   0%|          | 0.00/917M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7718f82553c14988b1c8de007162e250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00045-of-00064.parquet:   0%|          | 0.00/917M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb478204024478995c45790c1e9a55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00046-of-00064.parquet:   0%|          | 0.00/925M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a400f5614df9440b9a4b005ca221a129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00047-of-00064.parquet:   0%|          | 0.00/911M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8feedb40b247bfbbe505fae831c653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00048-of-00064.parquet:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72affaec8cda48bab5fbfb603a8ed2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00049-of-00064.parquet:   0%|          | 0.00/930M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1f91771a844be08bfedb3cf44c7d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00050-of-00064.parquet:   0%|          | 0.00/927M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be32b03923bc4b5ab62b33a6b70d2ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00051-of-00064.parquet:   0%|          | 0.00/927M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadbd4e2c45e41e0934c8859096e9241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00052-of-00064.parquet:   0%|          | 0.00/911M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983b9060f003431c83763c47a57a2c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00053-of-00064.parquet:   0%|          | 0.00/928M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415eaba382f54e149e309a2ec97924cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00054-of-00064.parquet:   0%|          | 0.00/917M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b784750d137e4bd28c954470b3ca62b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00055-of-00064.parquet:   0%|          | 0.00/929M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f7f95f06e5427c85ccdfdaa6cd28e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00056-of-00064.parquet:   0%|          | 0.00/939M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82c5c6a396c4341ac52b074ee976bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00057-of-00064.parquet:   0%|          | 0.00/924M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32aac655e34247d49abd5162a64db7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00058-of-00064.parquet:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f205481e5d4293a320d752312fa267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00059-of-00064.parquet:   0%|          | 0.00/910M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf4d281f175462e94d8fe1888ef84c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00060-of-00064.parquet:   0%|          | 0.00/958M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab383d25a1041d8a17e7e3b69909259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00061-of-00064.parquet:   0%|          | 0.00/934M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f7918d5002426e8c0dda8da403e7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00062-of-00064.parquet:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa81f367d14418da403651c3e213463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00063-of-00064.parquet:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb263c35d46496da4fbe5db35910bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40138809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517f37b7abc444c78fa4c40a43d6529f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Model\n",
    "# ------------------------------------------------\n",
    "\n",
    "from datasets import load_dataset\n",
    "starcoder_dataset = load_dataset(\"bigcode/the-stack-v2-train-smol-ids\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29332a01-0147-41a8-9e54-08f9b8d404e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Exact Prompt sample\n",
    "# ------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from transformers import AdamW\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, dataset, starcoder_dataset):\n",
    "        self.dataset = dataset\n",
    "        self.starcoder_dataset = starcoder_dataset\n",
    "        self.dataset_size = len(dataset)\n",
    "        self.starcoder_size = len(starcoder_dataset)\n",
    "        self.total_size = max(self.dataset_size, self.starcoder_size)\n",
    "        self.multiplier = self.total_size // self.dataset_size\n",
    "        self.remainder = self.total_size % self.dataset_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.starcoder_size:\n",
    "            starcoder_sample = self.starcoder_dataset[idx]\n",
    "        else:\n",
    "            starcoder_sample = self.starcoder_dataset[idx % self.starcoder_size]\n",
    "\n",
    "        dataset_idx = idx % self.dataset_size\n",
    "        dataset_sample = self.dataset[dataset_idx]\n",
    "\n",
    "        return dataset_sample, starcoder_sample\n",
    "\n",
    "combined_dataset = dataset # CombinedDataset(dataset, starcoder_dataset)\n",
    "train_loader = DataLoader(combined_dataset, batch_size=config.num_batches, num_workers=8,collate_fn=collate_fn) #shuffle=True,\n",
    "print(\"Train Loader done\")\n",
    "\n",
    "def train_exact(\n",
    "        model,           # The model being trained\n",
    "        optimizer,       # Optimizer for training\n",
    "        tokenizer,       # Tokenizer for encoding/decoding\n",
    "        config,\n",
    "        writer,\n",
    "        chat,                   # Function to generate output\n",
    "        train_loader,           # Training questions\n",
    "        reward_fn = None,              # Function to calculate rewards\n",
    "        group_size=16,          # Number of outputs to sample per question\n",
    "        learning_rate=1e-6,     # Learning rate\n",
    "        validation_batches=10,  # Number of batches to use for validation\n",
    "        model_path=None,        # Path to save model checkpoints\n",
    "        module_name=\"reasoning\",\n",
    "        epsilon=0.2,            # PPO clipping parameter\n",
    "        beta=0.04               # KL penalty coefficient\n",
    "):\n",
    "    # Store the current policy as the old policy\n",
    "    model.train()\n",
    "    train_layers = config.get_training_layers(model)\n",
    "    global_step = 0\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print(\"Enter epch:\", epoch)\n",
    "        epoch_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        for idx, qa in enumerate(train_loader):\n",
    "            print(\"Inner Loop:\", idx)\n",
    "            qa = qa.to(model.device)\n",
    "            lengths = [qa[i].shape[0] for i in range(len(qa))]\n",
    "            max_len = max(lengths)\n",
    "            print(\"max length\", lengths)\n",
    "            print(\"max token value:\", torch.max(qa).sum().item())\n",
    "            prompt_len = config.prompt_len\n",
    "            pad = config.pad\n",
    "            cur_in = qa[:, 0:-1]\n",
    "            cur_mask = torch.ones_like(cur_in).to(model.device)\n",
    "            expected = qa[:, 1:]\n",
    "\n",
    "            logits = model(input_ids=cur_in, attention_mask=cur_mask).logits\n",
    "            logits = logits.transpose(1, 2)\n",
    "            \n",
    "            print(logits.shape) # torch.Size([1, 256, 32001])\n",
    "            print(expected.shape) # torch.Size([1, 256])\n",
    "            logits = logits[:, :, :]\n",
    "            logits = logits.clamp(min=-100, max=100)\n",
    "            #loss = torch.nn.functional.cross_entropy(logits, expected)\n",
    "            loss = selective_log_softmax(logits, expected).sum()\n",
    "            print(\"Shape loss:\", loss.shape)\n",
    "\n",
    "            if False: #torch.isnan(loss).any():\n",
    "                print(\"Loss is NaN!\")\n",
    "                input_text = tokenizer.decode(cur_in[0], skip_special_tokens=True)\n",
    "                print(f\"Input text: {input_text}\")\n",
    "                output_text = tokenizer.decode(expected[0], skip_special_tokens=True)\n",
    "                print(f\"Output text: {output_text}\")\n",
    "                continue\n",
    "                \n",
    "            # Update policy model\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(train_layers, max_norm=0.1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            writer.add_scalar(\"Train/BatchLoss\", loss.item(), global_step)\n",
    "            global_step += 1\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        writer.add_scalar(\"Train/EpochLoss\", avg_epoch_loss, epoch)\n",
    "        print(f\"Epoch {epoch} average training loss: {avg_epoch_loss:.4f}\")\n",
    "        \n",
    "        # --------------------------\n",
    "        # Validation Phase (with reasoning test)\n",
    "        # --------------------------\n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for idx, question_ids, answer_ids in enumerate(train_loader):\n",
    "                    outputs = model(input_ids=question_ids, labels=answer_ids)\n",
    "                    loss = outputs.loss\n",
    "\n",
    "                    # Update policy model\n",
    "                    loss.backward()\n",
    "                    if idx % group_size == 0:\n",
    "                        optimizer.step()\n",
    "\n",
    "                    writer.add_scalar(\"Train/BatchLoss\", loss.item(), global_step)\n",
    "                    global_step += 1\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "                writer.add_scalar(\"Train/EpochLoss\", avg_epoch_loss, epoch)\n",
    "                print(f\"Epoch {epoch} average training loss: {avg_epoch_loss:.4f}\")\n",
    "            model.train()\n",
    "            config.save(epoch, model, optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "# --------------------------\n",
    "# Training Loop with Reasoning Verification\n",
    "# --------------------------\n",
    "train_exact(model, optimizer, tokenizer, config, writer, ReasoningChat.chat, train_loader)\n",
    "# Close the TensorBoard writer after training.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a8b65-1d20-4878-afb4-1e1e854d1e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
