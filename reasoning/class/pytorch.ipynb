{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64275fe7-5a29-4ce6-929e-0608a413d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29561177-93b3-4b00-92f2-d9409f923fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f6b036-9a59-4d4f-938c-e158c9fa30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = m1.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a3f560-0f6e-4d0b-8eb7-0288c86c102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40af797-9225-46db-a8d9-d6fdedcf9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759b649a-8a19-4d65-8e4a-51095344c55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt = torch.LongTensor([1,2,3,4])\n",
    "lt.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf767ec-8c83-407a-a0fb-de7c7e03c0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt = torch.ByteTensor([True, False, False, True])\n",
    "bt.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40af9de5-2a95-4074-aaa5-a02ab39ace9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2e523d-da5f-4c77-9af8-c57d4db46cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "def set_random_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "    \n",
    "set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3386dd2c-9b12-4578-ad32-2483587df47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  class\n",
       "0             5.1          3.5           1.4          0.2      0\n",
       "1             4.9          3.0           1.4          0.2      0\n",
       "2             4.7          3.2           1.3          0.2      0\n",
       "3             4.6          3.1           1.5          0.2      0\n",
       "4             5.0          3.6           1.4          0.2      0\n",
       "..            ...          ...           ...          ...    ...\n",
       "145           6.7          3.0           5.2          2.3      2\n",
       "146           6.3          2.5           5.0          1.9      2\n",
       "147           6.5          3.0           5.2          2.0      2\n",
       "148           6.2          3.4           5.4          2.3      2\n",
       "149           5.9          3.0           5.1          1.8      2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "df = pd.read_csv(\"./data/iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e860534-72c4-4004-bb37-7e9335a8db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.iloc[:, :-1].values\n",
    "y=df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da203bb-96b7-4113-a94c-342920b8e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8a5c0c1-c437-450c-921f-dea2a165f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bd0c2f1-7dc2-4a7a-8847-46e0a548b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00f4bbb8-57ab-424b-b05f-98dfa2b53e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7421fd428f50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10bee921-0226-427f-85dc-57b6c5585ba0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
       "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
       "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
       "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
       "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
       "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
       "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
       "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
       "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
       "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
       "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
       "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
       "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
       "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
       "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
       "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
       "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
       "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
       "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
       "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
       "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
       "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
       "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
       "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
       "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
       "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
       "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
       "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
       "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
       "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
       "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
       "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
       "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
       "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
       "        [4.9000, 3.1000, 1.5000, 0.2000],\n",
       "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
       "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
       "        [4.9000, 3.6000, 1.4000, 0.1000],\n",
       "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
       "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
       "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
       "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
       "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
       "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
       "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
       "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
       "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
       "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
       "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
       "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
       "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
       "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
       "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
       "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
       "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
       "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
       "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
       "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
       "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
       "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
       "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
       "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
       "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
       "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
       "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
       "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
       "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
       "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
       "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
       "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
       "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
       "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
       "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
       "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
       "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
       "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
       "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
       "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
       "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
       "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
       "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
       "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
       "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
       "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
       "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
       "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
       "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
       "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
       "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
       "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
       "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
       "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
       "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
       "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
       "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
       "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
       "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
       "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
       "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
       "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
       "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
       "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
       "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
       "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
       "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
       "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
       "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
       "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
       "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
       "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
       "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
       "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
       "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
       "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
       "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
       "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
       "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
       "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
       "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
       "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
       "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
       "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
       "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
       "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
       "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
       "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
       "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
       "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
       "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
       "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
       "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
       "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
       "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
       "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
       "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
       "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
       "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
       "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
       "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
       "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
       "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
       "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
       "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
       "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
       "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
       "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
       "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
       "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
       "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
       "        [5.9000, 3.0000, 5.1000, 1.8000]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71590bd3-c079-465f-a8ad-33267f644b93",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [4.9000, 3.6000, 1.4000, 0.1000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
      "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
      "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
      "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
      "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
      "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae4fa2a-0b38-43eb-9ec8-b1ad391a6c8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [4.9000, 3.6000, 1.4000, 0.1000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
      "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
      "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
      "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
      "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
      "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000]])\n"
     ]
    }
   ],
   "source": [
    "print(X.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f546bf02-419d-4e91-9ece-bdac64c417a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(X.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f0affdf-55f6-4e87-be90-7080a58da265",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(dataset)\n",
    "ratio_tn = 0.8\n",
    "n_tn = int(n*ratio_tn)\n",
    "n_te = n - n_tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17bfdc99-2502-41e0-a96b-756aba8699c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = random_split(dataset, [n_tn, n_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2df87d61-52e7-438f-a8ee-89db66363140",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 38\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:1295\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000\n",
    "n_feature = len(train_data[0][0])\n",
    "n_classes = 10  # adjust as needed\n",
    "\n",
    "# Define the classifier model.\n",
    "# Note: When using CrossEntropyLoss, remove the Softmax at the end.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_feature, n_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_feature, 10),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(10, n_classes)\n",
    "            # No Softmax layer because CrossEntropyLoss applies it internally.\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "model = Classifier(n_feature, n_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader = DataLoader(tarin_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(tarin_data)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Optionally, evaluate on test_data.\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8de3fc-746a-48eb-8107-52296e5f51ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
